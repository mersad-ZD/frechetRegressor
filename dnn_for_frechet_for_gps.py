# -*- coding: utf-8 -*-
"""DNN_for_frechet_for_gps.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1MT15AFOnQvltvIDZaC4Bx7-uFJfGYhlD
"""

!pip install similaritymeasures

from google.colab import drive
drive.mount('/content/drive')

import numpy as np
from numpy.random import randint
import pandas as pd
from sklearn.preprocessing import MinMaxScaler
from sklearn.preprocessing import StandardScaler
from sklearn.model_selection import train_test_split
from sklearn.model_selection import KFold
from sklearn.model_selection import cross_val_score
import matplotlib.pyplot as plt
from keras.models import Sequential
from keras.layers import Dense
from keras.wrappers.scikit_learn import KerasRegressor
from keras.layers import BatchNormalization
from sklearn.metrics import mean_squared_error
from sklearn.metrics import mean_absolute_error
from keras.callbacks import EarlyStopping
import similaritymeasures as sm
from numpy.random import seed
import time

tic = time.time()

seed(1)
import tensorflow
tensorflow.random.set_seed(2)

df1 = pd.read_csv(r"/content/drive/My Drive/Created_dataset/mydf1_100000_128_lat_long.csv")
df2 = pd.read_csv(r"/content/drive/My Drive/Created_dataset/mydf2_100000_128_lat_long.csv")
df3 = pd.read_csv(r"/content/drive/My Drive/Created_dataset/mydf3_100000_128_lat_long.csv")
df4 = pd.read_csv(r"/content/drive/My Drive/Created_dataset/mydf4_100000_128_lat_long.csv")
df5 = pd.read_csv(r"/content/drive/My Drive/Created_dataset/mydf5_100000_128_lat_long.csv")
df6 = pd.read_csv(r"/content/drive/My Drive/Created_dataset/mydf6_100000_128_lat_long.csv")
df7 = pd.read_csv(r"/content/drive/My Drive/Created_dataset/mydf7_100000_128_lat_long.csv")
# df8 = pd.read_csv(r"/content/drive/My Drive/Created_dataset/mydf8_100000_128_lat_long.csv")
# df9 = pd.read_csv(r"/content/drive/My Drive/Created_dataset/mydf9_100000_128_lat_long.csv")
#df10 = pd.read_csv(r"/content/drive/My Drive/Created_dataset/mydf10_100000_128_lat_long.csv")


# df4 = pd.concat([df1, df2], ignore_index=True)
dataset = pd.concat([df1, df2, df3, df4, df5, df6, df7], ignore_index=True)

X = dataset.iloc[:, :-1].values
Y = dataset.iloc[:, -1].values

scalar = StandardScaler()
X = scalar.fit_transform(X)
# #obj = scalar.fit(Y.reshape(-1, 1))
# Y = scalar.fit_transform(Y.reshape(-1, 1))

print("--------------")
X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size=0.1)
print("X_train.shape ", X_train.shape, y_train.shape)
print("X_test.shape",   X_test.shape, y_test.shape)
# -------------------------------------------------
es = EarlyStopping(monitor="val_loss", patience=100, mode="min")

# -------------------------------------------------
def build_model():
    regressor = Sequential()
    regressor.add(Dense(units=32, input_dim=512, activation="relu"))
    #regressor.add(BatchNormalization())
    regressor.add(Dense(units=16, activation="relu"))
    #regressor.add(BatchNormalization())
    #regressor.add(Dense(units=512, activation="relu"))
    # regressor.add(BatchNormalization())
    regressor.add(Dense(units=8, activation="relu"))
    #regressor.add(BatchNormalization())
    regressor.add(Dense(units=1))
    regressor.compile(optimizer="adam", loss="mse", metrics=['mae'])
    return regressor


regressor = KerasRegressor(build_fn=build_model, batch_size=32, epochs=150)  # validation_split=0.1

trained = regressor.fit(X_train, y_train, validation_data=(X_test, y_test),callbacks=[es],  verbose=1)

pred_train = regressor.predict(X_train)
print("train error ", np.sqrt(mean_squared_error(pred_train, y_train))) # shift o  run


# transform to real value
pred_test = regressor.predict(X_test)
# pred_test = scalar.inverse_transform(pred_test.reshape(-1, 1))
print("test error ", np.sqrt(mean_squared_error(pred_test, y_test)))

#-----------------------------------------------------------------------
print("train mean error ", mean_absolute_error(pred_train, y_train))
print("test mean error ", mean_absolute_error(pred_test, y_test))
# -----------------------------------------------------------------------


print("example ",  y_test[1],  pred_test[1])
print("example ",  y_test[2],  pred_test[2])
print("example ",  y_test[3],  pred_test[3])
print("example ",  y_test[8],  pred_test[8])
print("example ",  y_test[10],  pred_test[10])
print("example ",  y_test[20],  pred_test[20])
print("example ",  y_test[50],  pred_test[50])
print("example ",  y_test[100],  pred_test[100])

regressor.model.save("/content/drive/My Drive/lot_model/model_1000000_64.h5")

# plt.plot(trained.history['mean_squared_error'])
#plt.plot(trained.history['mean_absolute_error'])
plt.title('Mean Squared Error')
plt.plot(trained.history['loss'], label='train')
plt.plot(trained.history['val_loss'], label='test')
# plt.plot(trained.history['mean_absolute_percentage_error'])
# plt.plot(trained.history['cosine_proximity'])
plt.show()

toc = time.time()
print("time usage : ", str((toc - tic)*1000), " ms")

import numpy as np
import random as rn

vec = np.random.uniform(low=-90, high=90, size=(500,))
print(vec)
print(np.round(vec, 5))